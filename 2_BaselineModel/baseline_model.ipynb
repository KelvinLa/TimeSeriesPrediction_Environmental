{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "First, we select a simple model and that is just guessing the largest class. In the DatasetCharacteristics we saw, that every class has the same size, therefore we can use any class.\n",
    "\n",
    "It is very fast to implement and does not need training. Also it gives a first insight in to the topic and it is easy to understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Because we guess the classes at random, we do not need the features as base for the classifier, only the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_test = loadarff('../1_DatasetCharacteristics/data/InsectSound_TEST.arff')\n",
    "\n",
    "# dataset into dataframe\n",
    "df_test = pd.DataFrame(data_test[0])\n",
    "\n",
    "# Feature selection\n",
    "target = df_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first there are names as targets which need to be encoded into integers to use in the accuracy score in the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "y_test = le.fit_transform(df_test['target'])\n",
    "\n",
    "# printing label\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always predict the first target group\n",
    "y_pred = pd.Series([0 for _ in range(len(target))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "As Evaluation we use the accuracy and balanced accuracy score, because it is a classification and not a regression. The accuracy score tests, which classes are guessed right and calculates the relative amount for that. The balanced accuracy score also takes the size of the classes into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "# Your evaluation code here\n",
    "accuracy, balanced_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.1, which makes sense, because there are 10 classes of the same size. Because all classes have the same size the balanced accuracy score is the same as the accuracy score. This is not a really high result, which should be beaten by more complex models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
